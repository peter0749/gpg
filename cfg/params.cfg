# Robot Hand Geometry Parameters:
#   finger_width: the width of the finger
#   outer_diameter: the diameter of the robot hand (= maximum aperture plus 2 * finger width)
#   hand_depth: the finger length (measured from hand base to finger tip)
#   hand_height: the height of the hand
#   init_bite: the minimum distance between the fingertip and the side of the object that is oriented toward the hand
finger_width = 0.01
hand_outer_diameter = 0.10 # hand width
hand_depth = 0.11
hand_height = 0.01
init_bite = 0.01

# Preprocessing of Point Cloud
#   voxelize: if the point cloud gets voxelixed
#   remove_outliers: if statistical outliers are removed from the point cloud (used to remove noise)
#   workspace: the workspace of the robot manipulator
#   camera_pose: the pose of the camera that took the point cloud
voxelize = 0
remove_outliers = 0
workspace = 0.20 1.0 -0.28 0.28 0.005 1.0
#camera_pose = -1 0 0 0 0 1 0 0 0 0 -1 0 0.30 0 2.0 1 
camera_pose = 0 1 2 0.3 4 5 0.0 7 8 2.0

# Grasp Candidate Generation
#   num_samples: the number of samples to be drawn from the point cloud
#   num_threads: the number of CPU threads to be used
#   nn_radius: the radius for the neighborhood search
#   num_orientations: the number of robot hand orientations to evaluate
#   rotation_axis: the axis about which the point neighborhood gets rotated
num_samples = 100000000
max_samples = 100
num_threads = 8
nn_radius = 0.02
num_orientations = 16 # 22.5 deg
rotation_axis = 2
friction_coeff = 20.0
viable_thresh = 5
negative_sample = 0
remove_table = 1

# Visualization
#   plot_grasps: if the grasp candidates found are plotted with PCL
#   plot_normals: if the calculated surface normals are plotted with PCL
plot_grasps = 0
plot_candidates = 0
plot_normals = 0

# For generating multi-view dataset
output_merged_pcd = 0
